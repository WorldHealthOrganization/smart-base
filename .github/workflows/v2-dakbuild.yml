# DAK (Data Access Kit) Build Workflow
# This workflow includes DAK-specific features and calls the basic ghbuild workflow
# Features include: DMN questionnaires, schema generation, JSON-LD vocabularies, DAK API hub
# Created for v2 workflow architecture

name: DAK Build

# Controls when the action will run
on: 
  workflow_call: # Reusable by other workflows
    inputs:
      tx:
        required: false
        type: string
      generate_dmn_questionnaires:
        description: 'Generate DMN Questionnaires'
        required: false
        type: boolean
        default: true
      transform_dmn_files:
        description: 'Transform DMN files to HTML'
        required: false
        type: boolean
        default: true
      generate_valueset_schemas:
        description: 'Generate ValueSet JSON Schemas'
        required: false
        type: boolean
        default: true
      generate_logical_model_schemas:
        description: 'Generate Logical Model JSON Schemas'
        required: false
        type: boolean
        default: true
      generate_dak_api_hub:
        description: 'Generate DAK API Documentation Hub'
        required: false
        type: boolean
        default: true
      generate_jsonld_vocabularies:
        description: 'Generate JSON-LD Vocabularies from ValueSet expansions'
        required: false
        type: boolean
        default: true
  # Triggers the workflow on push or pull request events for any branch
  # This is a called workflow - it should not trigger directly on push/pull_request
  # The main dakbuild.yml wrapper calls this workflow

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
    inputs:
      tx:
        description: 'Optional Custom terminology server URL'
        required: false
      generate_dmn_questionnaires:
        description: 'Generate DMN Questionnaires'
        required: false
        type: boolean
        default: true
      transform_dmn_files:
        description: 'Transform DMN files to HTML'
        required: false
        type: boolean
        default: true
      generate_valueset_schemas:
        description: 'Generate ValueSet JSON Schemas'
        required: false
        type: boolean
        default: true
      generate_logical_model_schemas:
        description: 'Generate Logical Model JSON Schemas'
        required: false
        type: boolean
        default: true
      generate_dak_api_hub:
        description: 'Generate DAK API Documentation Hub'
        required: false
        type: boolean
        default: true
      generate_jsonld_vocabularies:
        description: 'Generate JSON-LD Vocabularies from ValueSet expansions'
        required: false
        type: boolean
        default: true

# Prevent concurrent deployments to avoid race conditions when updating gh-pages branch
concurrency:
  group: dak-deployment-${{ github.ref }}
  cancel-in-progress: false

jobs:
  # Pre-process job for DAK-specific tasks that need to run before IG publisher
  dak-preprocess:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Get branch name
        run: |
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            BRANCH_NAME="${{ github.head_ref }}"
          else
            BRANCH_NAME="${GITHUB_REF##*/}"
          fi
          echo "BRANCH_NAME=$BRANCH_NAME" >> $GITHUB_ENV

      - name: Validate DAK repository
        run: |
          echo "Validating DAK repository structure..."
          
          # Check if dak.json exists in repository root
          if [ ! -f "dak.json" ]; then
            echo "❌ ERROR: dak.json not found in repository root"
            echo "This repository is expected to be a DAK but does not contain a valid dak.json file."
            echo "The dakbuild workflow requires a valid dak.json in the root directory to proceed."
            exit 1
          fi
          
          # Validate that dak.json is valid JSON
          if ! jq . dak.json > /dev/null 2>&1; then
            echo "❌ ERROR: dak.json is not valid JSON"
            echo "Please check the syntax of your dak.json file."
            exit 1
          fi
          
          # Check for required DAK fields
          required_fields=("id" "name" "title" "description" "version" "status" "publicationUrl" "license" "publisher")
          missing_fields=()
          
          for field in "${required_fields[@]}"; do
            if ! jq -e ".$field" dak.json > /dev/null 2>&1; then
              missing_fields+=("$field")
            fi
          done
          
          if [ ${#missing_fields[@]} -gt 0 ]; then
            echo "❌ ERROR: dak.json is missing required fields:"
            printf "  - %s\n" "${missing_fields[@]}"
            echo ""
            echo "A valid DAK requires these fields to be present in dak.json."
            exit 1
          fi
          
          # Display DAK information
          echo "✅ Valid DAK repository detected:"
          echo "  ID: $(jq -r '.id' dak.json)"
          echo "  Name: $(jq -r '.name' dak.json)"
          echo "  Title: $(jq -r '.title' dak.json)"
          echo "  Version: $(jq -r '.version' dak.json)"
          echo "  Publication URL: $(jq -r '.publicationUrl' dak.json)"
          echo ""

      - name: Set feature flags
        uses: actions/github-script@v7
        env:
          INPUT_GENERATE_DMN_QUESTIONNAIRES: ${{ inputs.generate_dmn_questionnaires }}
          INPUT_TRANSFORM_DMN_FILES: ${{ inputs.transform_dmn_files }}
          INPUT_GENERATE_VALUESET_SCHEMAS: ${{ inputs.generate_valueset_schemas }}
          INPUT_GENERATE_LOGICAL_MODEL_SCHEMAS: ${{ inputs.generate_logical_model_schemas }}
          INPUT_GENERATE_DAK_API_HUB: ${{ inputs.generate_dak_api_hub }}
          INPUT_GENERATE_JSONLD_VOCABULARIES: ${{ inputs.generate_jsonld_vocabularies }}
        with:
          script: |
            const triggerType = context.eventName;
            console.log('Trigger type: ' + triggerType);
            
            // Normalize input handling for different trigger types
            function normalizeBoolean(inputValue, defaultValue) {
              // For automatic triggers (push/pull_request), use defaults
              if (triggerType !== 'workflow_dispatch' && triggerType !== 'workflow_call') {
                return defaultValue;
              }
              
              // For manual/call triggers, handle explicit boolean values
              switch (inputValue) {
                case 'true': return 'true';
                case 'false': return 'false';
                case '': return defaultValue;
                default: return defaultValue;
              }
            }
            
            // Get normalized values (defaults to true for all DAK features)
            const enableDmnQuestionnaires = normalizeBoolean(process.env.INPUT_GENERATE_DMN_QUESTIONNAIRES, 'true');
            const enableTransformDmn = normalizeBoolean(process.env.INPUT_TRANSFORM_DMN_FILES, 'true');
            const enableValuesetSchemas = normalizeBoolean(process.env.INPUT_GENERATE_VALUESET_SCHEMAS, 'true');
            const enableLogicalModelSchemas = normalizeBoolean(process.env.INPUT_GENERATE_LOGICAL_MODEL_SCHEMAS, 'true');
            const enableDakApiHub = normalizeBoolean(process.env.INPUT_GENERATE_DAK_API_HUB, 'true');
            const enableJsonldVocabularies = normalizeBoolean(process.env.INPUT_GENERATE_JSONLD_VOCABULARIES, 'true');
            
            core.exportVariable('ENABLE_DMN_QUESTIONNAIRES', enableDmnQuestionnaires);
            core.exportVariable('ENABLE_TRANSFORM_DMN', enableTransformDmn);
            core.exportVariable('ENABLE_VALUESET_SCHEMAS', enableValuesetSchemas);
            core.exportVariable('ENABLE_LOGICAL_MODEL_SCHEMAS', enableLogicalModelSchemas);
            core.exportVariable('ENABLE_DAK_API_HUB', enableDakApiHub);
            core.exportVariable('ENABLE_JSONLD_VOCABULARIES', enableJsonldVocabularies);
            
            console.log('DAK feature settings:');
            console.log('  Generate DMN Questionnaires: ' + enableDmnQuestionnaires);
            console.log('  Transform DMN files: ' + enableTransformDmn);
            console.log('  Generate ValueSet schemas: ' + enableValuesetSchemas);
            console.log('  Generate Logical Model schemas: ' + enableLogicalModelSchemas);
            console.log('  Generate DAK API hub: ' + enableDakApiHub);
            console.log('  Generate JSON-LD vocabularies: ' + enableJsonldVocabularies);

      - name: Generate DMN Questionnaires
        if: env.ENABLE_DMN_QUESTIONNAIRES == 'true'
        run: |
          echo "Generating FHIR Questionnaires from DMN files before IG publisher runs..."
          
          # Check if questionnaire generation files exist locally
          if [ ! -f "input/scripts/dmn_questionnaire_generator.py" ]; then
            echo "DMN questionnaire generator not found locally, downloading from smart-base repository..."
            
            # Create directories if they don't exist
            mkdir -p input/scripts
            
            # Function to download a file with fallback branches
            download_file() {
              local file_path="$1"
              local output_path="$2"
              
              # Try main branch first
              if curl -L -f -o "$output_path" "https://raw.githubusercontent.com/WorldHealthOrganization/smart-base/main/$file_path" 2>/dev/null; then
                printf "Downloaded %s from main branch\n" "$file_path"
                return 0
              fi
              
              # Fallback to current branch (for testing)
              if curl -L -f -o "$output_path" "https://raw.githubusercontent.com/WorldHealthOrganization/smart-base/$BRANCH_NAME/$file_path" 2>/dev/null; then
                printf "Downloaded %s from %s branch\n" "$file_path" "$BRANCH_NAME"
                return 0
              fi
              
              printf "Failed to download %s from any branch\n" "$file_path"
              return 1
            }
            
            # Download questionnaire generator from smart-base repository
            if ! download_file "input/scripts/dmn_questionnaire_generator.py" "input/scripts/dmn_questionnaire_generator.py"; then
              echo "Failed to download questionnaire generator, skipping questionnaire generation"
            fi
          else
            echo "Using local DMN questionnaire generator"
          fi
          
          # Install required Python dependencies for questionnaire generation
          pip install lxml
          
          # Run questionnaire generation if script is available
          if [ -f "input/scripts/dmn_questionnaire_generator.py" ]; then
            python3 input/scripts/dmn_questionnaire_generator.py
            echo "✅ Questionnaires generated successfully"
          else
            echo "⚠️ DMN questionnaire generator not available, skipping questionnaire generation"
          fi

      - name: Transform DMN files to HTML
        if: env.ENABLE_TRANSFORM_DMN == 'true'
        run: |
          echo "Transforming DMN files to HTML before IG publisher runs..."
          
          # Check if DMN transformation files exist locally
          if [ ! -f "input/scripts/transform_dmn.py" ] || [ ! -f "input/includes/dmn2html.xslt" ] || [ ! -f "input/includes/dmn.css" ]; then
            echo "DMN transformation files not found locally, downloading from smart-base repository..."
            
            # Create directories if they don't exist
            mkdir -p input/scripts input/includes
            
            # Function to download a file with fallback branches
            download_file() {
              local file_path="$1"
              local output_path="$2"
              
              # Try main branch first
              if curl -L -f -o "$output_path" "https://raw.githubusercontent.com/WorldHealthOrganization/smart-base/main/$file_path" 2>/dev/null; then
                printf "Downloaded %s from main branch\n" "$file_path"
                return 0
              fi
              
              # Fallback to current branch (for testing)
              if curl -L -f -o "$output_path" "https://raw.githubusercontent.com/WorldHealthOrganization/smart-base/$BRANCH_NAME/$file_path" 2>/dev/null; then
                printf "Downloaded %s from %s branch\n" "$file_path" "$BRANCH_NAME"
                return 0
              fi
              
              printf "Failed to download %s from any branch\n" "$file_path"
              return 1
            }
            
            # Download transformation files from smart-base repository
            download_success=true
            
            if ! download_file "input/scripts/transform_dmn.py" "input/scripts/transform_dmn.py"; then
              download_success=false
            fi
            
            if ! download_file "input/includes/dmn2html.xslt" "input/includes/dmn2html.xslt"; then
              download_success=false
            fi
            
            if ! download_file "input/includes/dmn.css" "input/includes/dmn.css"; then
              download_success=false
            fi
            
            if [ "$download_success" = true ]; then
              echo "Successfully downloaded all DMN transformation files"
            else
              echo "Failed to download some DMN transformation files"
            fi
          else
            echo "Using local DMN transformation files"
          fi
          
          # Install required Python dependencies for DMN transformation
          pip install lxml
          
          # Run DMN transformation if script is available
          if [ -f "input/scripts/transform_dmn.py" ]; then
            python3 input/scripts/transform_dmn.py
          else
            echo "DMN transformation script not available, skipping DMN transformation"
          fi

      - name: Configure DAK API hub settings
        if: env.ENABLE_DAK_API_HUB == 'true'
        run: |
          echo "DAK API generation enabled, configuring sushi-config.yaml..."
          
          # Install PyYAML for YAML processing
          pip install pyyaml
          
          # Check if update_sushi_config.py exists locally, download if not
          if [ ! -f "input/scripts/update_sushi_config.py" ]; then
            echo "update_sushi_config.py not found locally, downloading from smart-base repository..."
            
            # Create directories if they don't exist
            mkdir -p input/scripts
            
            # Function to download a file with fallback branches
            download_file() {
              local file_path="$1"
              local output_path="$2"
              
              # Try main branch first
              if curl -L -f -o "$output_path" "https://raw.githubusercontent.com/WorldHealthOrganization/smart-base/main/$file_path" 2>/dev/null; then
                printf "Downloaded %s from main branch\n" "$file_path"
                return 0
              fi
              
              # Fallback to current branch (for testing)
              if curl -L -f -o "$output_path" "https://raw.githubusercontent.com/WorldHealthOrganization/smart-base/$BRANCH_NAME/$file_path" 2>/dev/null; then
                printf "Downloaded %s from %s branch\n" "$file_path" "$BRANCH_NAME"
                return 0
              fi
              
              printf "Failed to download %s from any branch\n" "$file_path"
              return 1
            }
            
            # Download the update_sushi_config.py script
            if ! download_file "input/scripts/update_sushi_config.py" "input/scripts/update_sushi_config.py"; then
              echo "Failed to download update_sushi_config.py, continuing with existing configuration..."
            fi
          else
            echo "Using local update_sushi_config.py script"
          fi
          
          # Run the Python script to update sushi-config.yaml if available
          if [ -f "input/scripts/update_sushi_config.py" ]; then
            if python3 input/scripts/update_sushi_config.py; then
              echo "sushi-config.yaml processing completed"
              
              # Check if there are changes to commit
              if git diff --quiet sushi-config.yaml; then
                echo "No changes to sushi-config.yaml, continuing..."
              else
                echo "Committing sushi-config.yaml updates for DAK API configuration..."
                git config --local user.email "action@github.com"
                git config --local user.name "GitHub Action"
                git add sushi-config.yaml

                # Also add dak-api.md if it was created
                if [ -f "input/pagecontent/dak-api.md" ]; then
                  git add input/pagecontent/dak-api.md
                fi

                git commit -m "Auto-configure sushi-config.yaml for DAK API documentation"

                # Pull latest changes before pushing to avoid conflicts
                echo "Pulling latest changes before push..."
                if git pull --rebase origin $BRANCH_NAME; then
                  echo "Successfully pulled and rebased changes"
                else
                  echo "Pull/rebase failed, attempting merge strategy..."
                  git rebase --abort 2>/dev/null || true
                  if git pull --no-rebase origin $BRANCH_NAME; then
                    echo "Successfully pulled with merge strategy"
                  else
                    echo "❌ Failed to pull changes - there may be conflicts that need manual resolution"
                    echo "Attempting to push anyway..."
                  fi
                fi

                # Attempt to push with retry logic
                PUSH_RETRIES=3
                PUSH_SUCCESS=false

                for i in $(seq 1 $PUSH_RETRIES); do
                  printf "Push attempt %d of %d...\n" "$i" "$PUSH_RETRIES"
                  if git push origin $BRANCH_NAME; then
                    echo "✅ Successfully pushed changes"
                    PUSH_SUCCESS=true
                    break
                  else
                    echo "⚠️  Push attempt $i failed"
                    if [ $i -lt $PUSH_RETRIES ]; then
                      echo "Pulling latest changes before retry..."
                      git pull --no-rebase origin $BRANCH_NAME || echo "Pull failed, retrying push anyway..."
                      sleep 2
                    fi
                  fi
                done

                if [ "$PUSH_SUCCESS" = false ]; then
                  printf "❌ Failed to push after %d attempts\n" "$PUSH_RETRIES"
                  echo "This may indicate concurrent builds or permission issues"
                  echo "The build will continue, but sushi-config.yaml changes were not committed"
                  echo "Manual intervention may be required"
                fi
              fi
            else
              echo "Failed to update sushi-config.yaml, continuing with existing configuration..."
            fi
          else
            echo "update_sushi_config.py script not available, continuing with existing configuration..."
          fi

      - name: Upload preprocessed files
        uses: actions/upload-artifact@v4
        with:
          name: dak-preprocessed-files
          path: |
            input/
            sushi-config.yaml
          retention-days: 1

  # Call the build-only workflow
  call-ghbuild:
    needs: dak-preprocess
    uses: ./.github/workflows/v2-ghbuildonly.yml
    with:
      tx: ${{ inputs.tx }}
    secrets: inherit

  # Post-process job for DAK-specific tasks that need to run after IG publisher
  dak-postprocess:
    needs: call-ghbuild
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Download preprocessed files
        uses: actions/download-artifact@v4
        with:
          name: dak-preprocessed-files
          path: .

      - name: Download build output from ghbuild
        uses: actions/download-artifact@v4
        with:
          name: ig-build-output
          path: ./output/

      - name: Download qa.json (for reference)
        uses: actions/download-artifact@v4
        with:
          name: qa-json-artifact
          path: ./output/

      - name: Get branch name and feature flags
        run: |
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            BRANCH_NAME="${{ github.head_ref }}"
          else
            BRANCH_NAME="${GITHUB_REF##*/}"
          fi
          echo "BRANCH_NAME=$BRANCH_NAME" >> $GITHUB_ENV
          
          # Re-establish feature flags from preprocessing job
          TRIGGER_TYPE="${{ github.event_name }}"
          
          normalize_boolean() {
            local input_value="$1"
            local default_value="$2"
            
            if [ "$TRIGGER_TYPE" != "workflow_dispatch" ] && [ "$TRIGGER_TYPE" != "workflow_call" ]; then
              echo "$default_value"
              return
            fi
            
            case "$input_value" in
              "true")  echo "true" ;;
              "false") echo "false" ;;
              "")      echo "$default_value" ;;
              *)       echo "$default_value" ;;
            esac
          }
          
          ENABLE_VALUESET_SCHEMAS=$(normalize_boolean "${{ inputs.generate_valueset_schemas }}" "true")
          ENABLE_LOGICAL_MODEL_SCHEMAS=$(normalize_boolean "${{ inputs.generate_logical_model_schemas }}" "true")
          ENABLE_DAK_API_HUB=$(normalize_boolean "${{ inputs.generate_dak_api_hub }}" "true")
          ENABLE_JSONLD_VOCABULARIES=$(normalize_boolean "${{ inputs.generate_jsonld_vocabularies }}" "true")
          
          echo "ENABLE_VALUESET_SCHEMAS=$ENABLE_VALUESET_SCHEMAS" >> $GITHUB_ENV
          echo "ENABLE_LOGICAL_MODEL_SCHEMAS=$ENABLE_LOGICAL_MODEL_SCHEMAS" >> $GITHUB_ENV
          echo "ENABLE_DAK_API_HUB=$ENABLE_DAK_API_HUB" >> $GITHUB_ENV
          echo "ENABLE_JSONLD_VOCABULARIES=$ENABLE_JSONLD_VOCABULARIES" >> $GITHUB_ENV

      - name: Generate ValueSet JSON Schemas (after IG publisher)
        if: env.ENABLE_VALUESET_SCHEMAS == 'true'
        run: |
          echo "Generating ValueSet schemas from expansions.json after IG publisher..."
          if [ -f "./output/expansions.json" ]; then
            # Check if script exists locally first
            if [ -f "./input/scripts/generate_valueset_schemas.py" ]; then
              echo "Using local ValueSet schema generator..."
              python3 input/scripts/generate_valueset_schemas.py
              echo "VALUESET_SCHEMAS_GENERATED=true" >> $GITHUB_ENV
            else
              echo "Downloading ValueSet schema generator..."
              mkdir -p ./input/scripts
              curl -sSL https://raw.githubusercontent.com/WorldHealthOrganization/smart-base/main/input/scripts/generate_valueset_schemas.py \
                -o ./input/scripts/generate_valueset_schemas.py
              if [ -f "./input/scripts/generate_valueset_schemas.py" ]; then
                python3 input/scripts/generate_valueset_schemas.py
                echo "✅ ValueSet schemas generated successfully"
                echo "VALUESET_SCHEMAS_GENERATED=true" >> $GITHUB_ENV
              else
                echo "⚠️  Failed to download schema generator, skipping"
                echo "VALUESET_SCHEMAS_GENERATED=false" >> $GITHUB_ENV
              fi
            fi
          else
            echo "⚠️  expansions.json not found, skipping schema generation"
            echo "VALUESET_SCHEMAS_GENERATED=false" >> $GITHUB_ENV
          fi

      - name: Generate JSON-LD Vocabularies (after IG publisher)
        if: env.ENABLE_JSONLD_VOCABULARIES == 'true'
        run: |
          echo "Generating JSON-LD vocabularies from expansions.json after IG publisher..."
          if [ -f "./output/expansions.json" ]; then
            # Check if script exists locally first
            if [ -f "./input/scripts/generate_jsonld_vocabularies.py" ]; then
              echo "Using local JSON-LD vocabulary generator..."
              python3 input/scripts/generate_jsonld_vocabularies.py
              echo "JSONLD_VOCABULARIES_GENERATED=true" >> $GITHUB_ENV
            else
              echo "Downloading JSON-LD vocabulary generator..."
              mkdir -p ./input/scripts
              curl -sSL https://raw.githubusercontent.com/WorldHealthOrganization/smart-base/main/input/scripts/generate_jsonld_vocabularies.py \
                -o ./input/scripts/generate_jsonld_vocabularies.py
              if [ -f "./input/scripts/generate_jsonld_vocabularies.py" ]; then
                python3 input/scripts/generate_jsonld_vocabularies.py
                echo "✅ JSON-LD vocabularies generated successfully"
                echo "JSONLD_VOCABULARIES_GENERATED=true" >> $GITHUB_ENV
              else
                echo "⚠️  Failed to download JSON-LD vocabulary generator, skipping"
                echo "JSONLD_VOCABULARIES_GENERATED=false" >> $GITHUB_ENV
              fi
            fi
          else
            echo "⚠️  expansions.json not found, skipping JSON-LD vocabulary generation"
            echo "JSONLD_VOCABULARIES_GENERATED=false" >> $GITHUB_ENV
          fi

      - name: Generate Logical Model JSON Schemas (after IG publisher)
        if: env.ENABLE_LOGICAL_MODEL_SCHEMAS == 'true'
        run: |
          echo "Generating Logical Model schemas from StructureDefinition JSON files after IG publisher..."
          
          # Check if there are StructureDefinition files to process
          if find ./output -name "StructureDefinition-*.json" -print -quit | grep -q .; then
            echo "Found StructureDefinition files to process"
            # Check if script exists locally first
            if [ -f "./input/scripts/generate_logical_model_schemas.py" ]; then
              echo "Using local Logical Model schema generator..."
              python3 input/scripts/generate_logical_model_schemas.py output output
              echo "✅ Logical Model schemas generated successfully"
              echo "LOGICAL_MODEL_SCHEMAS_GENERATED=true" >> $GITHUB_ENV
            else
              echo "Downloading Logical Model schema generator..."
              mkdir -p ./input/scripts
              curl -sSL https://raw.githubusercontent.com/WorldHealthOrganization/smart-base/main/input/scripts/generate_logical_model_schemas.py \
                -o ./input/scripts/generate_logical_model_schemas.py
              if [ -f "./input/scripts/generate_logical_model_schemas.py" ]; then
                python3 input/scripts/generate_logical_model_schemas.py output output
                echo "✅ Logical Model schemas generated successfully"
                echo "LOGICAL_MODEL_SCHEMAS_GENERATED=true" >> $GITHUB_ENV
              else
                echo "⚠️  Failed to download Logical Model schema generator, skipping"
                echo "LOGICAL_MODEL_SCHEMAS_GENERATED=false" >> $GITHUB_ENV
              fi
            fi
          else
            echo "⚠️  No StructureDefinition JSON files found, skipping Logical Model schema generation"
            echo "LOGICAL_MODEL_SCHEMAS_GENERATED=false" >> $GITHUB_ENV
          fi

      - name: Generate DAK API Documentation (post-process HTML)  
        if: env.ENABLE_DAK_API_HUB == 'true'
        run: |
          echo "Post-processing DAK API documentation into generated HTML files..."
          
          # Check if there are schemas to document
          HAVE_SCHEMAS=false
          if [ -f "./output/ValueSets.schema.json" ] || [ -f "./output/LogicalModels.schema.json" ] || \
             find ./output -name "ValueSet-*.schema.json" -print -quit | grep -q . || \
             find ./output -name "*Model*.schema.json" -print -quit | grep -q . || \
             find ./output -name "ValueSet-*.jsonld" -print -quit | grep -q . || \
             [ -d "./input/images/openapi" ] && find ./input/images/openapi -name "*.json" -o -name "*.yaml" -o -name "*.yml" | grep -q .; then
            HAVE_SCHEMAS=true
            echo "Found schemas, JSON-LD vocabularies, or OpenAPI files to document"
          fi
          
          # Set fallback values for schema generation flags if not set
          VALUESET_SCHEMAS_GENERATED="${VALUESET_SCHEMAS_GENERATED:-false}"
          LOGICAL_MODEL_SCHEMAS_GENERATED="${LOGICAL_MODEL_SCHEMAS_GENERATED:-false}"
          JSONLD_VOCABULARIES_GENERATED="${JSONLD_VOCABULARIES_GENERATED:-false}"
          
          if [ "$HAVE_SCHEMAS" = true ] || [ "$VALUESET_SCHEMAS_GENERATED" = true ] || [ "$LOGICAL_MODEL_SCHEMAS_GENERATED" = true ] || [ "$JSONLD_VOCABULARIES_GENERATED" = true ]; then
            # Install required Python dependencies
            pip install pyyaml beautifulsoup4
            
            # Check if script exists locally first
            if [ -f "./input/scripts/generate_dak_api_hub.py" ]; then
              echo "Using local DAK API hub generator..."
              python3 input/scripts/generate_dak_api_hub.py output output
              echo "✅ DAK API documentation post-processed successfully"
            else
              echo "Downloading DAK API hub generator..."
              mkdir -p ./input/scripts
              curl -sSL https://raw.githubusercontent.com/WorldHealthOrganization/smart-base/main/input/scripts/generate_dak_api_hub.py \
                -o ./input/scripts/generate_dak_api_hub.py
              if [ -f "./input/scripts/generate_dak_api_hub.py" ]; then
                python3 input/scripts/generate_dak_api_hub.py output output
                echo "✅ DAK API documentation post-processed successfully"
              else
                echo "⚠️  Failed to download DAK API hub generator, skipping"
              fi
            fi
          else
            echo "⚠️  No schemas, JSON-LD vocabularies, or OpenAPI files found to document. Run schema generation steps first or ensure schemas are available."
            echo "     - Enable 'Generate ValueSet JSON Schemas' to generate ValueSet documentation"
            echo "     - Enable 'Generate Logical Model JSON Schemas' to generate Logical Model documentation"  
            echo "     - Enable 'Generate JSON-LD Vocabularies' to generate JSON-LD vocabulary documentation"
            echo "     - Or place OpenAPI/Swagger files in input/images/openapi/ directory"
            echo "Skipping DAK API documentation generation."
          fi

      - name: Upload final DAK output
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: dak-final-output
          path: ./output
          retention-days: 7

  # Call the deploy-only workflow
  call-ghdeploy:
    needs: dak-postprocess
    uses: ./.github/workflows/v2-ghdeployonly.yml
    with:
      artifact_name: dak-final-output
    secrets: inherit